# Athena Analytics Infrastructure

AWS Athenaåˆ†æç’°å¢ƒã‚’è‡ªå‹•æ§‹ç¯‰ã™ã‚‹Terraformæ§‹æˆã§ã™ã€‚S3ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Glue Crawlerã«ã‚ˆã‚‹è‡ªå‹•ã‚¹ã‚­ãƒ¼ãƒæ¤œå‡ºã€Athenaã§ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œã€QuickSightã§ã®å¯è¦–åŒ–ã¾ã§ã®å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚

## ğŸ“‹ æ§‹æˆæ¦‚è¦

ã“ã®Terraformæ§‹æˆã¯ä»¥ä¸‹ã®AWSãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™ï¼š

1. **AWS Glue** - ãƒ‡ãƒ¼ã‚¿ã‚«ã‚¿ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨Crawler
2. **Amazon S3** - ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã‚¯ã‚¨ãƒªçµæœä¿å­˜
3. **Amazon Athena** - ãƒ‡ãƒ¼ã‚¿ã‚¯ã‚¨ãƒªã¨ãƒ¯ãƒ¼ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—
4. **IAM** - å„ã‚µãƒ¼ãƒ“ã‚¹é–“ã®æ¨©é™ç®¡ç†
5. **QuickSighté€£æº** - ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ç”¨ã®æ¨©é™è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½

### AWS Accountæ¤œè¨¼æ©Ÿèƒ½ï¼ˆTerraformãƒã‚¤ãƒ†ã‚£ãƒ–ï¼‰
èª¤ã£ãŸAWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ã®å®Ÿè¡Œã‚’é˜²ããŸã‚ã€Terraformãƒã‚¤ãƒ†ã‚£ãƒ–ã®æ¤œè¨¼ã‚’ä½¿ç”¨ï¼š

```hcl
# ç‰¹å®šã®AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã§ã®å®Ÿè¡Œã‚’å¼·åˆ¶
expected_aws_account_id = "123456789012"
```

**CI/CDç’°å¢ƒã§ã®ä½¿ç”¨ä¾‹**:
```bash
# ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨
export TF_VAR_expected_aws_account_id="123456789012"
terraform plan
terraform apply
```

**å‹•ä½œ**:
1. ç¾åœ¨ã®AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’å–å¾—
2. `expected_aws_account_id`ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€å€¤ã‚’ç…§åˆ
3. ä¸ä¸€è‡´ã®å ´åˆã¯TerraformãŒã‚¨ãƒ©ãƒ¼ã§åœæ­¢
4. ç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—

### S3ãƒã‚±ãƒƒãƒˆæ¤œè¨¼æ©Ÿèƒ½ï¼ˆTerraformãƒã‚¤ãƒ†ã‚£ãƒ–ï¼‰
S3ãƒã‚±ãƒƒãƒˆã®å­˜åœ¨ç¢ºèªã¨ä½œæˆãƒãƒªã‚·ãƒ¼ã‚’åˆ¶å¾¡ï¼š

```hcl
# åŸºæœ¬è¨­å®š
auto_create_bucket = false           # ãƒã‚±ãƒƒãƒˆè‡ªå‹•ä½œæˆã‚’ç„¡åŠ¹åŒ–
require_bucket_exists = false        # æ—¢å­˜ãƒã‚±ãƒƒãƒˆã‚’è¦æ±‚ã—ãªã„
skip_bucket_validation = false       # ãƒã‚±ãƒƒãƒˆæ¤œè¨¼ã‚’å®Ÿè¡Œ

# CI/CDç’°å¢ƒå‘ã‘è¨­å®šä¾‹
require_bucket_exists = true         # æ—¢å­˜ãƒã‚±ãƒƒãƒˆã‚’è¦æ±‚
skip_bucket_validation = false       # ãƒã‚±ãƒƒãƒˆæ¤œè¨¼ã‚’å®Ÿè¡Œ
```

**æ¤œè¨¼ãƒ‘ã‚¿ãƒ¼ãƒ³**:
- `require_bucket_exists = true` â†’ ãƒã‚±ãƒƒãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
- `require_bucket_exists = false` + `auto_create_bucket = true` â†’ ãƒã‚±ãƒƒãƒˆã‚’è‡ªå‹•ä½œæˆ
- `skip_bucket_validation = true` â†’ ãƒã‚±ãƒƒãƒˆæ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¤–éƒ¨ã§ãƒã‚±ãƒƒãƒˆç®¡ç†ã™ã‚‹å ´åˆï¼‰

### å¾“æ¥ã®bashã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆéæ¨å¥¨ï¼‰
âš ï¸ **éæ¨å¥¨**: ä»¥ä¸‹ã®bashã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯SaaS/CIç’°å¢ƒã§ã¯å‹•ä½œã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼š

```bash
# å¾“æ¥ã®æ–¹æ³•ï¼ˆCI/CDç’°å¢ƒã§ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ï¼‰
./plan_with_confirmation.sh
./apply_with_confirmation.sh
```

**æ¨å¥¨**: ä¸Šè¨˜ã®Terraformãƒã‚¤ãƒ†ã‚£ãƒ–æ¤œè¨¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3 Bucket     â”‚    â”‚   AWS Glue      â”‚    â”‚     Athena      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”œâ”€ data/        â”‚â—„â”€â”€â”€â”¤ â”œâ”€ Database     â”‚â—„â”€â”€â”€â”¤ â”œâ”€ Workgroup    â”‚
â”‚ â”‚  â”œâ”€ type1/    â”‚    â”‚ â”œâ”€ Crawlers     â”‚    â”‚ â”œâ”€ Database     â”‚
â”‚ â”‚  â”œâ”€ type2/    â”‚    â”‚ â””â”€ Tables       â”‚    â”‚ â”œâ”€ Tables       â”‚
â”‚ â”‚  â””â”€ type3/    â”‚    â”‚                 â”‚    â”‚ â””â”€ Views        â”‚
â”‚ â””â”€ athena-      â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚    results/     â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚   QuickSight    â”‚
                                            â”‚                 â”‚
                                            â”‚ â”œâ”€ Data Source  â”‚
                                            â”‚ â”œâ”€ Datasets     â”‚
                                            â”‚ â””â”€ Dashboards   â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ ä½œæˆã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹

### AWS Glue
- **Catalog Database**: ãƒ‡ãƒ¼ã‚¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†
- **Crawlers**: å„ãƒ­ã‚°ã‚¿ã‚¤ãƒ—ç”¨ã®è‡ªå‹•ã‚¹ã‚­ãƒ¼ãƒæ¤œå‡º
- **IAM Role**: Crawlerå®Ÿè¡Œç”¨ã®æ¨©é™

### Amazon S3
- **Bucket**: ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³è‡ªå‹•ä½œæˆï¼‰
- **Encryption**: AES256æš—å·åŒ–
- **Public Access Block**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
- **Versioning**: ãƒ‡ãƒ¼ã‚¿ä¿è­·

### Amazon Athena
- **Workgroup**: ã‚¯ã‚¨ãƒªå®Ÿè¡Œç’°å¢ƒ
- **Database**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- **Named Queries**: ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³è¿½åŠ ã€ãƒ“ãƒ¥ãƒ¼ä½œæˆç”¨

### IAM
- **Athena Role**: S3ã¨Glueã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™
- **Glue Crawler Role**: S3ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Šæ¨©é™
- **QuickSight Role**: Athena/Glue/S3ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å‰ææ¡ä»¶

- AWS CLIè¨­å®šæ¸ˆã¿
- Terraform v1.0ä»¥ä¸Š
- ä»¥ä¸‹ã®AWSæ¨©é™ï¼š
  - S3: ãƒã‚±ãƒƒãƒˆä½œæˆãƒ»èª­ã¿æ›¸ã
  - Glue: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ä½œæˆ
  - Athena: ãƒ¯ãƒ¼ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
  - IAM: ãƒ­ãƒ¼ãƒ«ãƒ»ãƒãƒªã‚·ãƒ¼ä½œæˆ
  - QuickSight: ã‚µãƒ¼ãƒ“ã‚¹ãƒ­ãƒ¼ãƒ«ä½œæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

### 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

```bash
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
cp terraform.tfvars.example terraform.tfvars
```

#### å¿…é ˆå¤‰æ•°

```hcl
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè­˜åˆ¥å­
project           = "myproject"        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
env              = "dev"               # ç’°å¢ƒå
app              = "analytics"         # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å

# S3è¨­å®š
logs_bucket_name = "myproject-analytics-data"  # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒã‚±ãƒƒãƒˆå
logs_s3_prefix   = "data/logs"                 # ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
```

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¤‰æ•°

```hcl
# ãƒã‚±ãƒƒãƒˆè‡ªå‹•ä½œæˆ
auto_create_bucket = true              # å­˜åœ¨ã—ãªã„å ´åˆã®è‡ªå‹•ä½œæˆ

# æ¤œè¨¼è¨­å®šï¼ˆCI/CDç’°å¢ƒå‘ã‘ï¼‰
expected_aws_account_id = "123456789012"  # AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDæ¤œè¨¼
require_bucket_exists = false          # æ—¢å­˜ãƒã‚±ãƒƒãƒˆã‚’è¦æ±‚
skip_bucket_validation = false         # ãƒã‚±ãƒƒãƒˆæ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—

# QuickSighté€£æº
enable_quicksight = true               # QuickSightç”¨IAMãƒ­ãƒ¼ãƒ«ä½œæˆ

# Athenaãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š{project}_{env}_{app}_logså½¢å¼ã§ç’°å¢ƒã¨æ¡ˆä»¶ã‚’æ˜ç¢ºåŒ–ï¼‰
athena_database_name = "rcs_prd_web_logs"

# AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
aws_region = "ap-northeast-1"

# ã‚¿ã‚°
tags = {
  Owner       = "data-team"
  Environment = "development"
}
```

### 3. ãƒ­ã‚°ã‚¿ã‚¤ãƒ—è¨­å®š

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä»¥ä¸‹ã®ãƒ­ã‚°ã‚¿ã‚¤ãƒ—ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ï¼š

```hcl
log_types = {
  django_web = {
    table_name_suffix = "django_web"
    description       = "Django web application logs"
    schema = {
      date               = { type = "string", description = "Log timestamp" }
      source             = { type = "string", description = "Log source (stdout/stderr)" }
      log                = { type = "string", description = "Log message content" }
      container_id       = { type = "string", description = "Container ID" }
      container_name     = { type = "string", description = "Container name" }
      ec2_instance_id    = { type = "string", description = "EC2 instance ID" }
      ecs_cluster        = { type = "string", description = "ECS cluster name" }
      ecs_task_arn       = { type = "string", description = "ECS task ARN" }
      ecs_task_definition = { type = "string", description = "ECS task definition" }
    }
  }
  nginx_web = { /* åŒæ§˜ã®æ§‹é€  */ }
  error     = { /* åŒæ§˜ã®æ§‹é€  */ }
}
```

### 4. ãƒ‡ãƒ—ãƒ­ã‚¤

```bash
# åˆæœŸåŒ–
terraform init

# è¨ˆç”»ã®å®Ÿè¡Œ
terraform plan

# é©ç”¨ã®å®Ÿè¡Œ
terraform apply
```

### 5. CI/CDç’°å¢ƒã§ã®ä½¿ç”¨

#### GitHub Actions / GitLab CIä¾‹

```yaml
env:
  TF_VAR_expected_aws_account_id: "123456789012"
  TF_VAR_require_bucket_exists: "true"
  TF_VAR_skip_bucket_validation: "false"

steps:
  - name: Terraform Plan
    run: terraform plan

  - name: Terraform Apply
    run: terraform apply -auto-approve
```

#### Jenkinsä¾‹

```groovy
environment {
    TF_VAR_expected_aws_account_id = "123456789012"
    TF_VAR_require_bucket_exists = "true"
}

stage('Deploy') {
    steps {
        sh 'terraform init'
        sh 'terraform plan'
        sh 'terraform apply -auto-approve'
    }
}
```

#### æ¨å¥¨CI/CDè¨­å®š

```hcl
# terraform.tfvars (CI/CDç’°å¢ƒç”¨)
expected_aws_account_id = "123456789012"    # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
require_bucket_exists = true               # ãƒã‚±ãƒƒãƒˆã®äº‹å‰ä½œæˆã‚’è¦æ±‚
skip_bucket_validation = false             # ãƒã‚±ãƒƒãƒˆæ¤œè¨¼ã‚’å®Ÿè¡Œ
auto_create_bucket = false                 # è‡ªå‹•ä½œæˆã‚’ç„¡åŠ¹åŒ–
```

## ğŸ“ ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

S3ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼š

```
s3://myproject-analytics-data/
â”œâ”€â”€ data/logs/                    # logs_s3_prefix
â”‚   â”œâ”€â”€ django_web/              # ãƒ­ã‚°ã‚¿ã‚¤ãƒ—åˆ¥ãƒ•ã‚©ãƒ«ãƒ€
â”‚   â”‚   â”œâ”€â”€ year=2024/month=01/day=01/
â”‚   â”‚   â”‚   â””â”€â”€ data.csv
â”‚   â”‚   â””â”€â”€ year=2024/month=01/day=02/
â”‚   â”‚       â””â”€â”€ data.csv
â”‚   â”œâ”€â”€ nginx_web/
â”‚   â”‚   â””â”€â”€ year=2024/month=01/day=01/
â”‚   â”‚       â””â”€â”€ access.csv
â”‚   â””â”€â”€ error/
â”‚       â””â”€â”€ year=2024/month=01/day=01/
â”‚           â””â”€â”€ error.csv
â””â”€â”€ athena-query-results/         # Athenaã‚¯ã‚¨ãƒªçµæœ
    â””â”€â”€ 2024/01/01/
        â””â”€â”€ query-results.csv
```

## ğŸ”„ é‹ç”¨ãƒ•ãƒ­ãƒ¼

### 1. ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

```bash
# CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
aws s3 cp logs.csv s3://myproject-analytics-data/data/logs/django_web/year=2024/month=01/day=01/
```

### 2. Crawlerå®Ÿè¡Œ

```bash
# ä½œæˆã•ã‚ŒãŸCrawlerã‚’å®Ÿè¡Œ
aws glue start-crawler --name myproject-dev-django_web-crawler

# å®Ÿè¡ŒçŠ¶æ³ç¢ºèª
aws glue get-crawler --name myproject-dev-django_web-crawler
```

### 3. ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª

Athenaã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œï¼š

```sql
-- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§
SHOW TABLES IN myproject_dev_logs;

-- ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ç¢ºèª
DESCRIBE myproject_dev_logs.myproject_dev_django_web;

-- ãƒ‡ãƒ¼ã‚¿ç¢ºèª
SELECT * FROM myproject_dev_logs.myproject_dev_django_web LIMIT 10;
```

### 4. ãƒ“ãƒ¥ãƒ¼ä½œæˆ

Athenaã®ã€ŒSaved queriesã€ã‹ã‚‰å¯¾å¿œã™ã‚‹ãƒ“ãƒ¥ãƒ¼ä½œæˆã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œï¼š

```sql
-- ä¾‹ï¼šdjango_webã®ãƒ“ãƒ¥ãƒ¼ä½œæˆ
CREATE OR REPLACE VIEW myproject_dev_django_web_view AS
SELECT
    parsed_timestamp,
    log_date,
    log_hour,
    log_message,
    detected_log_level
FROM myproject_dev_logs.myproject_dev_django_web;
```

## ğŸ“Š åˆ†æã‚¯ã‚¨ãƒªä¾‹

### åŸºæœ¬çš„ãªåˆ†æ

```sql
-- æ—¥åˆ¥ãƒ­ã‚°ä»¶æ•°
SELECT
    log_date,
    COUNT(*) as log_count
FROM myproject_dev_logs.myproject_dev_django_web_view
WHERE log_date >= current_date - interval '7' day
GROUP BY log_date
ORDER BY log_date;

-- ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«åˆ¥é›†è¨ˆ
SELECT
    detected_log_level,
    COUNT(*) as count
FROM myproject_dev_logs.myproject_dev_error_view
WHERE log_date = current_date
GROUP BY detected_log_level;

-- æ™‚é–“åˆ¥ã‚¢ã‚¯ã‚»ã‚¹åˆ†æ
SELECT
    log_hour,
    COUNT(*) as access_count
FROM myproject_dev_logs.myproject_dev_nginx_web_view
WHERE log_date = current_date
GROUP BY log_hour
ORDER BY log_hour;
```

### é«˜åº¦ãªåˆ†æ

```sql
-- ã‚³ãƒ³ãƒ†ãƒŠåˆ¥ã‚¨ãƒ©ãƒ¼ç‡
SELECT
    container_name,
    COUNT(*) as total_logs,
    SUM(CASE WHEN detected_log_level = 'error' THEN 1 ELSE 0 END) as error_logs,
    CAST(SUM(CASE WHEN detected_log_level = 'error' THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*) * 100 as error_rate
FROM myproject_dev_logs.myproject_dev_django_web_view
WHERE log_date >= current_date - interval '1' day
GROUP BY container_name
HAVING COUNT(*) > 100
ORDER BY error_rate DESC;
```

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š

### æš—å·åŒ–
- **S3**: AES256 (SSE-S3)
- **Athena**: SSE_S3

### IAMæ¨©é™
- **æœ€å°æ¨©é™ã®åŸå‰‡**: å„ãƒ­ãƒ¼ãƒ«ã¯å¿…è¦æœ€å°é™ã®æ¨©é™ã®ã¿
- **ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™**: ç‰¹å®šã®S3ãƒã‚±ãƒƒãƒˆã¨Glueãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
- **æ¡ä»¶ä»˜ãã‚¢ã‚¯ã‚»ã‚¹**: ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ¶é™ãªã©ã®æ¡ä»¶ã‚’è¨­å®š

### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
- **ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãƒ–ãƒ­ãƒƒã‚¯**: S3ãƒã‚±ãƒƒãƒˆã¸ã®æ„å›³ã—ãªã„ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’é˜²æ­¢

## ğŸ› ï¸ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### æ–°ã—ã„ãƒ­ã‚°ã‚¿ã‚¤ãƒ—ã®è¿½åŠ 

```hcl
# terraform.tfvarsã«è¿½åŠ 
log_types = {
  # æ—¢å­˜ã®ã‚¿ã‚¤ãƒ—...

  api_logs = {
    table_name_suffix = "api_logs"
    description       = "API access logs"
    schema = {
      timestamp    = { type = "string", description = "Request timestamp" }
      method       = { type = "string", description = "HTTP method" }
      path         = { type = "string", description = "Request path" }
      status_code  = { type = "int", description = "HTTP status code" }
      response_time = { type = "double", description = "Response time in ms" }
    }
  }
}
```

### ãƒ“ãƒ¥ãƒ¼ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

`templates/create_view.sql`ã‚’ç·¨é›†ã—ã¦ã€ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«åˆã‚ã›ãŸåˆ†æé …ç›®ã‚’è¿½åŠ ã€‚

### ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³æˆ¦ç•¥

```sql
-- å¹´æœˆæ—¥ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³
CREATE TABLE my_table (
  data string,
  log_message string
)
PARTITIONED BY (
  year string,
  month string,
  day string
)
```

## ğŸ“ˆ ç›£è¦–ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### CloudWatchç›£è¦–

```bash
# Crawlerå®Ÿè¡ŒçŠ¶æ³ã®ç›£è¦–
aws logs describe-log-groups --log-group-name-prefix "/aws-glue/crawlers"

# Athenaã‚¯ã‚¨ãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹
aws cloudwatch get-metric-statistics \
  --namespace AWS/Athena \
  --metric-name QueryExecutionTime \
  --start-time 2024-01-01T00:00:00Z \
  --end-time 2024-01-02T00:00:00Z \
  --period 3600 \
  --statistics Average
```

### è‡ªå‹•åŒ–

```bash
# Crawlerå®šæœŸå®Ÿè¡Œï¼ˆCloudWatch Eventsï¼‰
aws events put-rule \
  --name daily-crawler \
  --schedule-expression "cron(0 2 * * ? *)"

aws events put-targets \
  --rule daily-crawler \
  --targets "Id"="1","Arn"="arn:aws:glue:region:account:crawler/crawler-name"
```

### ã‚³ã‚¹ãƒˆæœ€é©åŒ–

1. **ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³æˆ¦ç•¥**: æ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ã‚¹ã‚­ãƒ£ãƒ³é‡ã‚’å‰Šæ¸›
2. **ãƒ‡ãƒ¼ã‚¿åœ§ç¸®**: Parquetå½¢å¼ã¸ã®å¤‰æ›ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›
3. **ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†**: å¤ã„ãƒ‡ãƒ¼ã‚¿ã®IA/Glacierã¸ã®ç§»è¡Œ
4. **ã‚¯ã‚¨ãƒªæœ€é©åŒ–**: WHEREã‚¯ãƒ©ã‚¦ã‚¹ã§ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³çµã‚Šè¾¼ã¿

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **CrawlerãŒãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ãªã„**
   ```bash
   # ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèª
   aws s3 ls s3://bucket/path/ --recursive

   # IAMæ¨©é™ç¢ºèª
   aws iam simulate-principal-policy \
     --policy-source-arn arn:aws:iam::account:role/glue-role \
     --action-names s3:GetObject \
     --resource-arns arn:aws:s3:::bucket/path/*
   ```

2. **Athenaã‚¯ã‚¨ãƒªãŒå¤±æ•—ã™ã‚‹**
   ```sql
   -- ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
   DESCRIBE table_name;

   -- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ç¢ºèª
   SHOW PARTITIONS table_name;
   ```

3. **æ¨©é™ã‚¨ãƒ©ãƒ¼**
   ```bash
   # CloudTrailã§APIå‘¼ã³å‡ºã—ã‚’ç¢ºèª
   aws logs filter-log-events \
     --log-group-name CloudTrail/AthenaAccess \
     --start-time 1640995200000
   ```

## ğŸ“š å‡ºåŠ›æƒ…å ±

Terraformé©ç”¨å¾Œã€ä»¥ä¸‹ã®æƒ…å ±ãŒå‡ºåŠ›ã•ã‚Œã¾ã™ï¼š

- **æ¥ç¶šæƒ…å ±**: AWS ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã€ãƒªã‚½ãƒ¼ã‚¹å
- **S3ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³**: ãƒ‡ãƒ¼ã‚¿ä¿å­˜å ´æ‰€ã¨ã‚¯ã‚¨ãƒªçµæœä¿å­˜å ´æ‰€
- **Glueæƒ…å ±**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åã€Crawlerå
- **Athenaæƒ…å ±**: ãƒ¯ãƒ¼ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—åã€åå‰ä»˜ãã‚¯ã‚¨ãƒª
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æƒ…å ±**: IAMãƒ­ãƒ¼ãƒ«ARNã€æš—å·åŒ–è¨­å®š
- **å®Ÿè¡Œã‚¬ã‚¤ãƒ‰**: æ¬¡ã«å®Ÿè¡Œã™ã¹ãæ‰‹é †

## ğŸ¤ ã‚µãƒãƒ¼ãƒˆ

æŠ€è¡“çš„ãªå•é¡Œã‚„ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã®ç›¸è«‡ã«ã¤ã„ã¦ã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Issueãƒˆãƒ©ãƒƒã‚«ãƒ¼ã¾ã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚
